{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91720,"databundleVersionId":13345277,"sourceType":"competition"},{"sourceId":12699678,"sourceType":"datasetVersion","datasetId":8025996}],"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-25T05:53:33.955014Z","iopub.execute_input":"2025-09-25T05:53:33.955466Z","iopub.status.idle":"2025-09-25T05:53:34.351845Z","shell.execute_reply.started":"2025-09-25T05:53:33.955440Z","shell.execute_reply":"2025-09-25T05:53:34.350563Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# # 🎵 End-to-End BPM Prediction Pipeline","metadata":{}},{"cell_type":"markdown","source":"## 📌 Objective\nThe goal of this notebook is to predict **BeatsPerMinute (BPM)** for music tracks using audio-derived features.  \nThe task is framed as a **regression problem**, and predictions are submitted in Kaggle competition format.\n","metadata":{}},{"cell_type":"markdown","source":"# ***Setup and Data Loading***","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import skew\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as catb\nimport optuna \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T05:53:39.077299Z","iopub.execute_input":"2025-09-25T05:53:39.077787Z","iopub.status.idle":"2025-09-25T05:53:47.396448Z","shell.execute_reply.started":"2025-09-25T05:53:39.077761Z","shell.execute_reply":"2025-09-25T05:53:47.395519Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ***📊 Dataset Overview***","metadata":{}},{"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e9/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e9/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T05:53:48.008709Z","iopub.execute_input":"2025-09-25T05:53:48.009057Z","iopub.status.idle":"2025-09-25T05:53:50.447197Z","shell.execute_reply.started":"2025-09-25T05:53:48.009019Z","shell.execute_reply":"2025-09-25T05:53:50.446229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(train)\ndisplay(test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ****🔍 Exploratory Data Analysis (EDA)****","metadata":{}},{"cell_type":"markdown","source":"- Inspected data structure, shapes, and basic statistics.  \n- Checked missing values and feature distributions.  \n- Visualized the target (`BeatsPerMinute`) to understand skewness and outliers.  \n- Explored feature correlations to identify the most predictive variables.","metadata":{}},{"cell_type":"code","source":"print(\"--First 5 rows --\")\ndisplay(train.head())\nprint(\"\\n--First 5 rows --\")\ntest.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Display basic information about the dataframes","metadata":{}},{"cell_type":"code","source":"print(\"Train data info:\")\ndisplay(train.info())\nprint(\"\\nTest data info:\")\ndisplay(test.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Check for missing values","metadata":{}},{"cell_type":"code","source":"\nprint(\"\\nMissing values in train data:\")\nprint(train.isnull().sum())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nMissing values in test data:\")\nprint(test.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize the distribution of the target variable","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train['BeatsPerMinute'], kde=True)\nplt.title('Distribution of BeatsPerMinute')\nplt.xlabel('BeatsPerMinute')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### *****Handle Outliers*****","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Visualize outliers for df\nnumerical_cols_df = train.select_dtypes(include=['float64', 'int64']).columns\nnum_plots = len(numerical_cols_df)\nnum_cols = 3\nnum_rows = (num_plots + num_cols - 1) // num_cols\n\nplt.figure(figsize=(15, num_rows * 5))\nfor i, col in enumerate(numerical_cols_df):\n    plt.subplot(num_rows, num_cols, i + 1)\n    sns.boxplot(data=train, y=col)\n    plt.title(f'Outliers in {col} (Train)')\nplt.tight_layout()\nplt.show()\n\n# Visualize outliers for test_df\nnumerical_cols_test_df = test.select_dtypes(include=['float64', 'int64']).columns\nnum_plots = len(numerical_cols_test_df)\nnum_cols = 3\nnum_rows = (num_plots + num_cols - 1) // num_cols\n\nplt.figure(figsize=(15, num_rows * 5))\nfor i, col in enumerate(numerical_cols_test_df):\n    plt.subplot(num_rows, num_cols, i + 1)\n    sns.boxplot(data=test, y=col)\n    plt.title(f'Outliers in {col} (Test)')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"***(optional)***","metadata":{}},{"cell_type":"code","source":"def outlier_plot(data, exclude_columns, box_color='pink', median_color='brown', whisker_color='purple'):\n    columns = data.drop(exclude_columns, axis=1, errors='ignore').columns\n    \n    n_cols = len(columns)\n    n_rows = (n_cols + 1) // 2 \n    \n    plt.figure(figsize=(15, 5 * n_rows)) \n    \n    for i, column in enumerate(columns, 1):\n        plt.subplot(n_rows, 2, i)\n        plt.boxplot(\n            data[column].dropna(), \n            vert=False,\n            patch_artist=True,  \n            boxprops=dict(facecolor=box_color, color=whisker_color),\n            medianprops=dict(color=median_color),\n            whiskerprops=dict(color=whisker_color),\n            capprops=dict(color=whisker_color),\n            flierprops=dict(marker='o', color=whisker_color, markersize=5)\n        )\n        plt.title(f'{column}')\n        plt.xlabel(column)\n        plt.grid(False)\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_outliers(data , outlier_columns):\n    \n    for column in outlier_columns:\n        Q1 = data[column].quantile(0.25)\n        Q3 = data[column].quantile(0.75)\n        IQR = Q3 - Q1\n        \n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        \n        data = data[\n            (data[column] >= lower_bound) & (data[column] <= upper_bound)\n        ]\n    \n    return data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"OUTLIER_COLUMNS = ['AudioLoudness' , 'VocalContent' , 'AcousticQuality' ,'RhythmScore' ,'InstrumentalScore' , 'LivePerformanceLikelihood' , 'TrackDurationMs']\n\ntrain = remove_outliers(train , OUTLIER_COLUMNS)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"outlier_plot(train, ['BeatsPerMinute' , 'id'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ****Visualize Feature Correlations****","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nsns.heatmap(train.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Heatmap of Train Data ')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nsns.heatmap(train.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Heatmap of Train Data')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # ****⚙️ Feature Engineering****","metadata":{}},{"cell_type":"markdown","source":"***Create new features that might be helpful for the model.***","metadata":{}},{"cell_type":"markdown","source":"- Applied transformations to handle skewed distributions (e.g., **logTransformer**, scaling).   \n- Created additional engineered features (e.g., squared terms, interaction terms) to capture non-linear relationships.  \n- Ensured consistent preprocessing across train, validation, and test sets.","metadata":{}},{"cell_type":"markdown","source":"Type one ","metadata":{}},{"cell_type":"code","source":"# Create interaction features\ntrain['Vocal_Instrumental_Ratio'] = train['VocalContent'] / (train['InstrumentalScore'] + 1e-6)\ntest['Vocal_Instrumental_Ratio'] = test['VocalContent'] / (test['InstrumentalScore'] + 1e-6)\n\ntrain['Energy_AudioLoudness'] = train['Energy'] * train['AudioLoudness']\ntest['Energy_AudioLoudness'] = test['Energy'] * test['AudioLoudness']\n\n# Create new feature: AudioPerDuration\ntrain['AudioPerDuration'] = train['AudioLoudness'] / train['TrackDurationMs']\ntest['AudioPerDuration'] = test['AudioLoudness'] / test['TrackDurationMs']\n# Create polynomial features (e.g., square of MoodScore)\ntrain['MoodScore_sq'] = train['MoodScore']**2\ntest['MoodScore_sq'] = test['MoodScore']**2\n\n# Create features based on combinations of other features\ntrain['Rhythm_Energy'] = train['RhythmScore'] * train['Energy']\ntest['Rhythm_Energy'] = test['RhythmScore'] * test['Energy']\n\ntrain['Acoustic_Instrumental'] = train['AcousticQuality'] * train['InstrumentalScore']\ntest['Acoustic_Instrumental'] = test['AcousticQuality'] * test['InstrumentalScore']\n\n# Create new feature: MoodLikelihoodRatio\n# Add a small constant to the denominator to avoid division by zero\ntrain['MoodLikelihoodRatio'] = train['MoodScore'] / (train['LivePerformanceLikelihood'] + 1e-6)\ntest['MoodLikelihoodRatio'] = test['MoodScore'] / (test['LivePerformanceLikelihood'] + 1e-6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T05:56:37.681532Z","iopub.execute_input":"2025-09-25T05:56:37.681836Z","iopub.status.idle":"2025-09-25T05:56:37.754158Z","shell.execute_reply.started":"2025-09-25T05:56:37.681813Z","shell.execute_reply":"2025-09-25T05:56:37.753123Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *****Data preprocessing*****","metadata":{}},{"cell_type":"markdown","source":"  # scale numerical features, and encode categorical features if any.","metadata":{}},{"cell_type":"markdown","source":"***(Optional)***","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import PowerTransformer\n\n# Identify numerical columns from the training data (excluding 'id' and 'BeatsPerMinute')\nnumerical_cols_train = train.select_dtypes(include=np.number).columns.tolist()\nnumerical_cols_train.remove('id')\nif 'BeatsPerMinute' in numerical_cols_train:\n    numerical_cols_train.remove('BeatsPerMinute')\n\n# Ensure the test data has the same numerical columns as the training data\nnumerical_cols_test = [col for col in numerical_cols_train if col in test.columns]\n\n# Apply Yeo-Johnson transformation\npt_yeo_johnson = PowerTransformer(method='yeo-johnson')\n\n# Fit on training data and transform both train and test data using the training columns\ntrain[numerical_cols_train] = pt_yeo_johnson.fit_transform(train[numerical_cols_train])\ntest[numerical_cols_test] = pt_yeo_johnson.transform(test[numerical_cols_test])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # log transformation","metadata":{}},{"cell_type":"code","source":"# Create a list of columns that are safe for log transformation\nlog_transform_cols = [\n    \"RhythmScore\",\"AudioLoudness\", \"VocalContent\", \"AcousticQuality\", \"InstrumentalScore\",\n    \"LivePerformanceLikelihood\", \"MoodScore\", \"Energy\"\n]\n\n# Apply a different transformation to AudioLoudness to make it non-negative\n# A common method is to shift the data by adding a positive constant.\n# Here we will shift by the absolute minimum value + 1 to ensure all values are positive.\nmin_loudness = train['AudioLoudness'].min()\ntrain['AudioLoudness_transformed'] = np.log1p(train['AudioLoudness'] - min_loudness + 1)\ntest['AudioLoudness_transformed'] = np.log1p(test['AudioLoudness'] - min_loudness + 1)\n\n# Now apply log transformation to the remaining numerical columns\ntrain_log = train.copy()\ntest_log = test.copy()\n\ntrain_log[log_transform_cols] = np.log1p(train_log[log_transform_cols])\ntest_log[log_transform_cols] = np.log1p(test_log[log_transform_cols])\n\nprint(\"Train dataframe after log transformation:\")\ndisplay(train_log.head())\n\nprint(\"\\nTest dataframe after log transformation:\")\ndisplay(test_log.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T05:56:29.518657Z","iopub.execute_input":"2025-09-25T05:56:29.519000Z","iopub.status.idle":"2025-09-25T05:56:29.907786Z","shell.execute_reply.started":"2025-09-25T05:56:29.518975Z","shell.execute_reply":"2025-09-25T05:56:29.906976Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *****Feature Scaling*****","metadata":{}},{"cell_type":"markdown","source":"# MinMaxScaler","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Select numerical columns, excluding 'id', that are common to both dataframes\nnumerical_cols = train.select_dtypes(include=['float64', 'int64']).columns.intersection(test.select_dtypes(include=['float64', 'int64']).columns)\n\n# Initialize StandardScaler\nscaler =MinMaxScaler()\n\n# Fit and transform on the training data\ntrain_scaled = train.copy()\ntrain_scaled[numerical_cols] = scaler.fit_transform(train_scaled[numerical_cols])\n\n### Transform the test data using the same scaler\ntest_scaled = test.copy()\ntest_scaled[numerical_cols] = scaler.transform(test_scaled[numerical_cols])\n\n#print(\"Scaled train dataframe:\")\n#display(train.head())\n\n#print(\"\\nScaled test dataframe:\")\n#display(test.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T05:56:56.769850Z","iopub.execute_input":"2025-09-25T05:56:56.770176Z","iopub.status.idle":"2025-09-25T05:56:57.372124Z","shell.execute_reply.started":"2025-09-25T05:56:56.770150Z","shell.execute_reply":"2025-09-25T05:56:57.371244Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# StandardScaler","metadata":{}},{"cell_type":"markdown","source":"(Optional)","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.preprocessing import StandardScaler\n\n# Select numerical columns, excluding 'id', that are common to both dataframes\nnumerical_cols = train.select_dtypes(include=['float64', 'int64']).columns.drop('id').intersection(test.select_dtypes(include=['float64', 'int64']).columns.drop('id'))\n\n# Initialize StandardScaler\nscaler = StandardScaler()\n\n# Fit and transform on the training data\ntrain_scaled = train.copy()\ntrain_scaled[numerical_cols] = scaler.fit_transform(train_scaled[numerical_cols])\n\n# Transform the test data using the same scaler\ntest_scaled = test.copy()\ntest_scaled[numerical_cols] = scaler.transform(test_scaled[numerical_cols])\n\n#print(\"Scaled train dataframe:\")\n#display(train.head())\n\n#print(\"\\nScaled test dataframe:\")\n#display(test.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test = test.drop(['id'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train.drop(['id', 'BeatsPerMinute'], axis=1)\ny = train['BeatsPerMinute']\n\n\n\nprint(\"X shape:\", X.shape)\nprint(\"y shape:\", y.shape)\nprint(\"X_test shape:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T05:57:20.133428Z","iopub.execute_input":"2025-09-25T05:57:20.133711Z","iopub.status.idle":"2025-09-25T05:57:20.198317Z","shell.execute_reply.started":"2025-09-25T05:57:20.133691Z","shell.execute_reply":"2025-09-25T05:57:20.197097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_val shape:\", X_val.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_val shape:\", y_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T05:58:01.633683Z","iopub.execute_input":"2025-09-25T05:58:01.633987Z","iopub.status.idle":"2025-09-25T05:58:01.833607Z","shell.execute_reply.started":"2025-09-25T05:58:01.633956Z","shell.execute_reply":"2025-09-25T05:58:01.832294Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training and evaluation","metadata":{}},{"cell_type":"markdown","source":"## 🤖 Modeling\nWe trained and evaluated multiple regression models using **RMSE** as the evaluation metric:","metadata":{}},{"cell_type":"markdown","source":"# LGBM model using optuna ","metadata":{}},{"cell_type":"markdown","source":" **LightGBM with Optuna Tuning**\n   - Performed hyperparameter optimization with Optuna.  \n   - Selected the best parameters and retrained the model on the full dataset.  \n   - Predictions saved as `submissionb.csv`.","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\n\ndef objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 31, 512),\n        'max_depth': trial.suggest_int('max_depth', -1, 12),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n        'random_state': 42,\n        'n_jobs': -1\n    }\n    model = LGBMRegressor(**params)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_val)\n    rmse = mean_squared_error(y_val, preds, squared=False)\n    return rmse\n\n# Run Optuna optimization\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50)\n\nprint(\"Best RMSE:\", study.best_value)\nprint(\"Best params:\", study.best_params)\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # train + val into full dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Concatenate back train + val into full dataset\nX_full = pd.concat([X_train, X_val], axis=0)\ny_full = pd.concat([y_train, y_val], axis=0)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Get best params from Optuna","metadata":{}},{"cell_type":"code","source":"# 1. Get best params from Optuna\nbest_params = study.best_params\n\n# 2. Retrain on full train data (combine train+val)\nbest_model = LGBMRegressor(**best_params, random_state=42, n_jobs=-1)\n\nbest_model.fit(X_full, y_full, eval_metric=\"rmse\")\n\n# 3. Predict on X_test\ny_test_pred = best_model.predict(X_test)\n\nprint(\"Test predictions:\", y_test_pred[:10])  # show first 10 predictions\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# submission of lgbm using optuna ","metadata":{}},{"cell_type":"code","source":"# Choose one of the models for submission or average their predictions\n# Example using LGBM predictions:\nsubmission_df = pd.DataFrame({'id': test['id'], 'BeatsPerMinute':y_test_pred})\n# Example using averaged predictions (if you want to try ensembling):\n# averaged_predictions = (lgbm_test_pred + xgb_test_pred + catboost_test_pred) / 3\n# submission_df = pd.DataFrame({'id': test_df['id'], 'BeatsPerMinute': averaged_predictions})\n\n\n# Save the submission file\nsubmission_df.to_csv('submissionb.csv', index=False)\n\nprint(\"Submission file created successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model : 1","metadata":{}},{"cell_type":"markdown","source":"# LGBM model (basic)","metadata":{}},{"cell_type":"markdown","source":" **LightGBM (Basic)**\n   - Used predefined parameters without tuning.  \n   - Served as a baseline LightGBM model.  \n   - Predictions saved as `submission.csv`.","metadata":{}},{"cell_type":"code","source":"# Initialize the LGBM model\nlgbm = LGBMRegressor(learning_rate =  0.02493303813836915,num_leaves = 34,max_depth = 13,reg_alpha =0.07319459385373907,reg_lambda = 0.08870554420170793,subsample= 0.5514983899131313,random_state=42)\n\n# Train the LGBM model\nprint(\"Training LGBM model...\")\nlgbm.fit(X_train, y_train)\n\n# Evaluate the LGBM model\ny_pred_lgbm = lgbm.predict(X_val)\nrmse_lgbm = mean_squared_error(y_val, y_pred_lgbm)**0.5\nprint(f\"LGBM RMSE on validation data: {rmse_lgbm}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model : 2","metadata":{}},{"cell_type":"markdown","source":"# XGBoost model","metadata":{}},{"cell_type":"markdown","source":" **XGBoost**\n   - Trained an **XGBRegressor** with default parameters.  \n   - Evaluated RMSE on validation data.  \n   - Predictions saved as `submission2.csv`.","metadata":{}},{"cell_type":"code","source":"# Initialize the XGBoost model\nxgb = XGBRegressor(random_state=42)\n\n# Train the XGBoost model\nprint(\"Training XGBoost model...\")\nxgb.fit(X_train, y_train)\n\n# Evaluate the XGBoost model\ny_pred_xgb = xgb.predict(X_val)\nrmse_xgb = mean_squared_error(y_val, y_pred_xgb)**0.5\nprint(f\"XGBoost RMSE on validation data: {rmse_xgb}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model : 3","metadata":{}},{"cell_type":"markdown","source":"# catboost model","metadata":{}},{"cell_type":"markdown","source":"**CatBoost**\n   - Trained a **CatBoostRegressor** with random_state = 42.  \n   - Evaluated RMSE on validation data.  \n   - Predictions saved as `submission3.csv`.","metadata":{}},{"cell_type":"code","source":"!pip install catboost","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\n# Initialize the CatBoost model\ncatboost = CatBoostRegressor(random_state=42, verbose=0) # verbose=0 to suppress output during training\n\n# Train the CatBoost model\nprint(\"Training CatBoost model...\")\ncatboost.fit(X_train, y_train)\n\n# Evaluate the CatBoost model\ny_pred_catboost = catboost.predict(X_val)\nrmse_catboost = mean_squared_error(y_val, y_pred_catboost)**0.5\nprint(f\"CatBoost RMSE on validation data: {rmse_catboost}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions on the test data using the trained models\nlgbm_test_pred = lgbm.predict(X_test)\nxgb_test_pred = xgb.predict(X_test)\ncatboost_test_pred = catboost.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:12:27.601515Z","iopub.execute_input":"2025-09-21T17:12:27.602155Z","iopub.status.idle":"2025-09-21T17:12:28.117187Z","shell.execute_reply.started":"2025-09-21T17:12:27.602130Z","shell.execute_reply":"2025-09-21T17:12:28.116495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Choose one of the models for submission or average their predictions\n# Example using LGBM predictions:\nsubmission_df = pd.DataFrame({'id': test['id'], 'BeatsPerMinute': lgbm_test_pred})\n# Example using averaged predictions (if you want to try ensembling):\n# averaged_predictions = (lgbm_test_pred + xgb_test_pred + catboost_test_pred) / 3\n# submission_df = pd.DataFrame({'id': test_df['id'], 'BeatsPerMinute': averaged_predictions})\n\n\n# Save the submission file\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"Submission file created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:12:32.467127Z","iopub.execute_input":"2025-09-21T17:12:32.467677Z","iopub.status.idle":"2025-09-21T17:12:32.956126Z","shell.execute_reply.started":"2025-09-21T17:12:32.467652Z","shell.execute_reply":"2025-09-21T17:12:32.955402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Choose one of the models for submission or average their predictions\n# Example using LGBM predictions:\nsubmission_df = pd.DataFrame({'id': test['id'], 'BeatsPerMinute': xgb_test_pred})\n# Example using averaged predictions (if you want to try ensembling):\n# averaged_predictions = (lgbm_test_pred + xgb_test_pred + catboost_test_pred) / 3\n# submission_df = pd.DataFrame({'id': test_df['id'], 'BeatsPerMinute': averaged_predictions})\n\n\n# Save the submission file\nsubmission_df.to_csv('submission2.csv', index=False)\n\nprint(\"Submission file created successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Choose one of the models for submission or average their predictions\n# Example using LGBM predictions:\nsubmission_df = pd.DataFrame({'id': test['id'], 'BeatsPerMinute': catboost_test_pred})\n# Example using averaged predictions (if you want to try ensembling):\n# averaged_predictions = (lgbm_test_pred + xgb_test_pred + catboost_test_pred) / 3\n# submission_df = pd.DataFrame({'id': test_df['id'], 'BeatsPerMinute': averaged_predictions})\n\n\n# Save the submission file\nsubmission_df.to_csv('submission3.csv', index=False)\n\nprint(\"Submission file created successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🏁 Submission\n- Multiple submission files were generated:\n  - `submissionb.csv` → LGBM with Optuna  \n  - `submission.csv` → Basic LGBM  \n  - `submission2.csv` → XGBoost  \n  - `submission3.csv` → CatBoost  ","metadata":{}},{"cell_type":"markdown","source":"## ✅ Conclusion\n- LightGBM with Optuna tuning achieved the best validation performance.","metadata":{}},{"cell_type":"code","source":"# 🎵 End-to-End BPM Prediction Pipeline¶\n📌 Objective\nThe goal of this notebook is to predict BeatsPerMinute (BPM) for music tracks using audio-derived features.\nThe task is framed as a regression problem, and predictions are submitted in Kaggle competition format.\n\nSetup and Data Loading\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import skew\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as catb\nimport optuna \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport warnings\nwarnings.filterwarnings('ignore')\n📊 Dataset Overview\n# Load the data\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e9/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e9/test.csv')\ndisplay(train)\ndisplay(test)\n🔍 Exploratory Data Analysis (EDA)\nInspected data structure, shapes, and basic statistics.\nChecked missing values and feature distributions.\nVisualized the target (BeatsPerMinute) to understand skewness and outliers.\nExplored feature correlations to identify the most predictive variables.\nprint(\"--First 5 rows --\")\ndisplay(train.head())\nprint(\"\\n--First 5 rows --\")\ntest.head()\nDisplay basic information about the dataframes\nprint(\"Train data info:\")\ndisplay(train.info())\nprint(\"\\nTest data info:\")\ndisplay(test.info())\nCheck for missing values\nprint(\"\\nMissing values in train data:\")\nprint(train.isnull().sum())\nprint(\"\\nMissing values in test data:\")\nprint(test.isnull().sum())\nVisualize the distribution of the target variable\nplt.figure(figsize=(10, 6))\nsns.histplot(train['BeatsPerMinute'], kde=True)\nplt.title('Distribution of BeatsPerMinute')\nplt.xlabel('BeatsPerMinute')\nplt.ylabel('Frequency')\nplt.show()\n*Handle Outliers*\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Visualize outliers for df\nnumerical_cols_df = train.select_dtypes(include=['float64', 'int64']).columns\nnum_plots = len(numerical_cols_df)\nnum_cols = 3\nnum_rows = (num_plots + num_cols - 1) // num_cols\n\nplt.figure(figsize=(15, num_rows * 5))\nfor i, col in enumerate(numerical_cols_df):\n    plt.subplot(num_rows, num_cols, i + 1)\n    sns.boxplot(data=train, y=col)\n    plt.title(f'Outliers in {col} (Train)')\nplt.tight_layout()\nplt.show()\n\n# Visualize outliers for test_df\nnumerical_cols_test_df = test.select_dtypes(include=['float64', 'int64']).columns\nnum_plots = len(numerical_cols_test_df)\nnum_cols = 3\nnum_rows = (num_plots + num_cols - 1) // num_cols\n\nplt.figure(figsize=(15, num_rows * 5))\nfor i, col in enumerate(numerical_cols_test_df):\n    plt.subplot(num_rows, num_cols, i + 1)\n    sns.boxplot(data=test, y=col)\n    plt.title(f'Outliers in {col} (Test)')\nplt.tight_layout()\nplt.show()\n(optional)\n\ndef outlier_plot(data, exclude_columns, box_color='pink', median_color='brown', whisker_color='purple'):\n    columns = data.drop(exclude_columns, axis=1, errors='ignore').columns\n    \n    n_cols = len(columns)\n    n_rows = (n_cols + 1) // 2 \n    \n    plt.figure(figsize=(15, 5 * n_rows)) \n    \n    for i, column in enumerate(columns, 1):\n        plt.subplot(n_rows, 2, i)\n        plt.boxplot(\n            data[column].dropna(), \n            vert=False,\n            patch_artist=True,  \n            boxprops=dict(facecolor=box_color, color=whisker_color),\n            medianprops=dict(color=median_color),\n            whiskerprops=dict(color=whisker_color),\n            capprops=dict(color=whisker_color),\n            flierprops=dict(marker='o', color=whisker_color, markersize=5)\n        )\n        plt.title(f'{column}')\n        plt.xlabel(column)\n        plt.grid(False)\n\n    plt.tight_layout()\n    plt.show()\ndef remove_outliers(data , outlier_columns):\n    \n    for column in outlier_columns:\n        Q1 = data[column].quantile(0.25)\n        Q3 = data[column].quantile(0.75)\n        IQR = Q3 - Q1\n        \n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        \n        data = data[\n            (data[column] >= lower_bound) & (data[column] <= upper_bound)\n        ]\n    \n    return data\nOUTLIER_COLUMNS = ['AudioLoudness' , 'VocalContent' , 'AcousticQuality' ,'RhythmScore' ,'InstrumentalScore' , 'LivePerformanceLikelihood' , 'TrackDurationMs']\n\ntrain = remove_outliers(train , OUTLIER_COLUMNS)\noutlier_plot(train, ['BeatsPerMinute' , 'id'])\nVisualize Feature Correlations\nplt.figure(figsize=(12, 10))\nsns.heatmap(train.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Heatmap of Train Data ')\nplt.show()\nplt.figure(figsize=(12, 10))\nsns.heatmap(train.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Heatmap of Train Data')\nplt.show()\n⚙️ Feature Engineering\nCreate new features that might be helpful for the model.\n\nApplied transformations to handle skewed distributions (e.g., logTransformer, scaling).\nCreated additional engineered features (e.g., squared terms, interaction terms) to capture non-linear relationships.\nEnsured consistent preprocessing across train, validation, and test sets.\nType one\n\n# Create interaction features\ntrain['Vocal_Instrumental_Ratio'] = train['VocalContent'] / (train['InstrumentalScore'] + 1e-6)\ntest['Vocal_Instrumental_Ratio'] = test['VocalContent'] / (test['InstrumentalScore'] + 1e-6)\n\ntrain['Energy_AudioLoudness'] = train['Energy'] * train['AudioLoudness']\ntest['Energy_AudioLoudness'] = test['Energy'] * test['AudioLoudness']\n\n# Create new feature: AudioPerDuration\ntrain['AudioPerDuration'] = train['AudioLoudness'] / train['TrackDurationMs']\ntest['AudioPerDuration'] = test['AudioLoudness'] / test['TrackDurationMs']\n# Create polynomial features (e.g., square of MoodScore)\ntrain['MoodScore_sq'] = train['MoodScore']**2\ntest['MoodScore_sq'] = test['MoodScore']**2\n\n# Create features based on combinations of other features\ntrain['Rhythm_Energy'] = train['RhythmScore'] * train['Energy']\ntest['Rhythm_Energy'] = test['RhythmScore'] * test['Energy']\n\ntrain['Acoustic_Instrumental'] = train['AcousticQuality'] * train['InstrumentalScore']\ntest['Acoustic_Instrumental'] = test['AcousticQuality'] * test['InstrumentalScore']\n\n# Create new feature: MoodLikelihoodRatio\n# Add a small constant to the denominator to avoid division by zero\ntrain['MoodLikelihoodRatio'] = train['MoodScore'] / (train['LivePerformanceLikelihood'] + 1e-6)\ntest['MoodLikelihoodRatio'] = test['MoodScore'] / (test['LivePerformanceLikelihood'] + 1e-6)\n*Data preprocessing*\nscale numerical features, and encode categorical features if any.\n(Optional)\n\nfrom sklearn.preprocessing import PowerTransformer\n\n# Identify numerical columns from the training data (excluding 'id' and 'BeatsPerMinute')\nnumerical_cols_train = train.select_dtypes(include=np.number).columns.tolist()\nnumerical_cols_train.remove('id')\nif 'BeatsPerMinute' in numerical_cols_train:\n    numerical_cols_train.remove('BeatsPerMinute')\n\n# Ensure the test data has the same numerical columns as the training data\nnumerical_cols_test = [col for col in numerical_cols_train if col in test.columns]\n\n# Apply Yeo-Johnson transformation\npt_yeo_johnson = PowerTransformer(method='yeo-johnson')\n\n# Fit on training data and transform both train and test data using the training columns\ntrain[numerical_cols_train] = pt_yeo_johnson.fit_transform(train[numerical_cols_train])\ntest[numerical_cols_test] = pt_yeo_johnson.transform(test[numerical_cols_test])\nlog transformation\n# Create a list of columns that are safe for log transformation\nlog_transform_cols = [\n    \"RhythmScore\",\"AudioLoudness\", \"VocalContent\", \"AcousticQuality\", \"InstrumentalScore\",\n    \"LivePerformanceLikelihood\", \"MoodScore\", \"Energy\"\n]\n\n# Apply a different transformation to AudioLoudness to make it non-negative\n# A common method is to shift the data by adding a positive constant.\n# Here we will shift by the absolute minimum value + 1 to ensure all values are positive.\nmin_loudness = train['AudioLoudness'].min()\ntrain['AudioLoudness_transformed'] = np.log1p(train['AudioLoudness'] - min_loudness + 1)\ntest['AudioLoudness_transformed'] = np.log1p(test['AudioLoudness'] - min_loudness + 1)\n\n# Now apply log transformation to the remaining numerical columns\ntrain_log = train.copy()\ntest_log = test.copy()\n\ntrain_log[log_transform_cols] = np.log1p(train_log[log_transform_cols])\ntest_log[log_transform_cols] = np.log1p(test_log[log_transform_cols])\n\nprint(\"Train dataframe after log transformation:\")\ndisplay(train_log.head())\n\nprint(\"\\nTest dataframe after log transformation:\")\ndisplay(test_log.head())\n*Feature Scaling*\nMinMaxScaler\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Select numerical columns, excluding 'id', that are common to both dataframes\nnumerical_cols = train.select_dtypes(include=['float64', 'int64']).columns.intersection(test.select_dtypes(include=['float64', 'int64']).columns)\n\n# Initialize StandardScaler\nscaler =MinMaxScaler()\n\n# Fit and transform on the training data\ntrain_scaled = train.copy()\ntrain_scaled[numerical_cols] = scaler.fit_transform(train_scaled[numerical_cols])\n\n### Transform the test data using the same scaler\ntest_scaled = test.copy()\ntest_scaled[numerical_cols] = scaler.transform(test_scaled[numerical_cols])\n\n#print(\"Scaled train dataframe:\")\n#display(train.head())\n\n#print(\"\\nScaled test dataframe:\")\n#display(test.head())\nStandardScaler\n(Optional)\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Select numerical columns, excluding 'id', that are common to both dataframes\nnumerical_cols = train.select_dtypes(include=['float64', 'int64']).columns.drop('id').intersection(test.select_dtypes(include=['float64', 'int64']).columns.drop('id'))\n\n# Initialize StandardScaler\nscaler = StandardScaler()\n\n# Fit and transform on the training data\ntrain_scaled = train.copy()\ntrain_scaled[numerical_cols] = scaler.fit_transform(train_scaled[numerical_cols])\n\n# Transform the test data using the same scaler\ntest_scaled = test.copy()\ntest_scaled[numerical_cols] = scaler.transform(test_scaled[numerical_cols])\n\n#print(\"Scaled train dataframe:\")\n#display(train.head())\n\n#print(\"\\nScaled test dataframe:\")\n#display(test.head())\nX_test = test.drop(['id'], axis=1)\nX = train.drop(['id', 'BeatsPerMinute'], axis=1)\ny = train['BeatsPerMinute']\n\n\n\nprint(\"X shape:\", X.shape)\nprint(\"y shape:\", y.shape)\nprint(\"X_test shape:\", X_test.shape)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_val shape:\", X_val.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_val shape:\", y_val.shape)\nTraining and evaluation\n🤖 Modeling\nWe trained and evaluated multiple regression models using RMSE as the evaluation metric:\n\nLGBM model using optuna\nLightGBM with Optuna Tuning\n\nPerformed hyperparameter optimization with Optuna.\nSelected the best parameters and retrained the model on the full dataset.\nPredictions saved as submissionb.csv.\nimport optuna\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\n\ndef objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 31, 512),\n        'max_depth': trial.suggest_int('max_depth', -1, 12),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n        'random_state': 42,\n        'n_jobs': -1\n    }\n    model = LGBMRegressor(**params)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_val)\n    rmse = mean_squared_error(y_val, preds, squared=False)\n    return rmse\n\n# Run Optuna optimization\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50)\n\nprint(\"Best RMSE:\", study.best_value)\nprint(\"Best params:\", study.best_params)\ntrain + val into full dataset\nimport pandas as pd\n\n# Concatenate back train + val into full dataset\nX_full = pd.concat([X_train, X_val], axis=0)\ny_full = pd.concat([y_train, y_val], axis=0)\nGet best params from Optuna\n# 1. Get best params from Optuna\nbest_params = study.best_params\n\n# 2. Retrain on full train data (combine train+val)\nbest_model = LGBMRegressor(**best_params, random_state=42, n_jobs=-1)\n\nbest_model.fit(X_full, y_full, eval_metric=\"rmse\")\n\n# 3. Predict on X_test\ny_test_pred = best_model.predict(X_test)\n\nprint(\"Test predictions:\", y_test_pred[:10])  # show first 10 predictions\nsubmission of lgbm using optuna\n# Choose one of the models for submission or average their predictions\n# Example using LGBM predictions:\nsubmission_df = pd.DataFrame({'id': test['id'], 'BeatsPerMinute':y_test_pred})\n# Example using averaged predictions (if you want to try ensembling):\n# averaged_predictions = (lgbm_test_pred + xgb_test_pred + catboost_test_pred) / 3\n# submission_df = pd.DataFrame({'id': test_df['id'], 'BeatsPerMinute': averaged_predictions})\n\n\n# Save the submission file\nsubmission_df.to_csv('submissionb.csv', index=False)\n\nprint(\"Submission file created successfully!\")\nModel : 1\nLGBM model (basic)\nLightGBM (Basic)\n\nUsed predefined parameters without tuning.\nServed as a baseline LightGBM model.\nPredictions saved as submission.csv.\n# Initialize the LGBM model\nlgbm = LGBMRegressor(learning_rate =  0.02493303813836915,num_leaves = 34,max_depth = 13,reg_alpha =0.07319459385373907,reg_lambda = 0.08870554420170793,subsample= 0.5514983899131313,random_state=42)\n\n# Train the LGBM model\nprint(\"Training LGBM model...\")\nlgbm.fit(X_train, y_train)\n\n# Evaluate the LGBM model\ny_pred_lgbm = lgbm.predict(X_val)\nrmse_lgbm = mean_squared_error(y_val, y_pred_lgbm)**0.5\nprint(f\"LGBM RMSE on validation data: {rmse_lgbm}\")\nModel : 2\nXGBoost model\nXGBoost\n\nTrained an XGBRegressor with default parameters.\nEvaluated RMSE on validation data.\nPredictions saved as submission2.csv.\n# Initialize the XGBoost model\nxgb = XGBRegressor(random_state=42)\n\n# Train the XGBoost model\nprint(\"Training XGBoost model...\")\nxgb.fit(X_train, y_train)\n\n# Evaluate the XGBoost model\ny_pred_xgb = xgb.predict(X_val)\nrmse_xgb = mean_squared_error(y_val, y_pred_xgb)**0.5\nprint(f\"XGBoost RMSE on validation data: {rmse_xgb}\")\nModel : 3\ncatboost model\nCatBoost\n\nTrained a CatBoostRegressor with random_state = 42.\nEvaluated RMSE on validation data.\nPredictions saved as submission3.csv.\n!pip install catboost\nfrom catboost import CatBoostRegressor\n\n# Initialize the CatBoost model\ncatboost = CatBoostRegressor(random_state=42, verbose=0) # verbose=0 to suppress output during training\n\n# Train the CatBoost model\nprint(\"Training CatBoost model...\")\ncatboost.fit(X_train, y_train)\n\n# Evaluate the CatBoost model\ny_pred_catboost = catboost.predict(X_val)\nrmse_catboost = mean_squared_error(y_val, y_pred_catboost)**0.5\nprint(f\"CatBoost RMSE on validation data: {rmse_catboost}\")\n# Make predictions on the test data using the trained models\nlgbm_test_pred = lgbm.predict(X_test)\nxgb_test_pred = xgb.predict(X_test)\ncatboost_test_pred = catboost.predict(X_test)\n# Choose one of the models for submission or average their predictions\n# Example using LGBM predictions:\nsubmission_df = pd.DataFrame({'id': test['id'], 'BeatsPerMinute': lgbm_test_pred})\n# Example using averaged predictions (if you want to try ensembling):\n# averaged_predictions = (lgbm_test_pred + xgb_test_pred + catboost_test_pred) / 3\n# submission_df = pd.DataFrame({'id': test_df['id'], 'BeatsPerMinute': averaged_predictions})\n\n\n# Save the submission file\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"Submission file created successfully!\")\n# Choose one of the models for submission or average their predictions\n# Example using LGBM predictions:\nsubmission_df = pd.DataFrame({'id': test['id'], 'BeatsPerMinute': xgb_test_pred})\n# Example using averaged predictions (if you want to try ensembling):\n# averaged_predictions = (lgbm_test_pred + xgb_test_pred + catboost_test_pred) / 3\n# submission_df = pd.DataFrame({'id': test_df['id'], 'BeatsPerMinute': averaged_predictions})\n\n\n# Save the submission file\nsubmission_df.to_csv('submission2.csv', index=False)\n\nprint(\"Submission file created successfully!\")\n# Choose one of the models for submission or average their predictions\n# Example using LGBM predictions:\nsubmission_df = pd.DataFrame({'id': test['id'], 'BeatsPerMinute': catboost_test_pred})\n# Example using averaged predictions (if you want to try ensembling):\n# averaged_predictions = (lgbm_test_pred + xgb_test_pred + catboost_test_pred) / 3\n# submission_df = pd.DataFrame({'id': test_df['id'], 'BeatsPerMinute': averaged_predictions})\n\n\n# Save the submission file\nsubmission_df.to_csv('submission3.csv', index=False)\n\nprint(\"Submission file created successfully!\")\n🏁 Submission\nMultiple submission files were generated:\nsubmissionb.csv → LGBM with Optuna\nsubmission.csv → Basic LGBM\nsubmission2.csv → XGBoost\nsubmission3.csv → CatBoost\n✅ Conclusion\nLightGBM with Optuna tuning achieved the best validation performance.","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}